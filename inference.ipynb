{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23134,"status":"ok","timestamp":1673311695166,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"lXrDtQFQXPz5","outputId":"a61fea68-295b-4f1c-d842-873b73a869e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting feature_engine\n","  Downloading feature_engine-1.5.2-py2.py3-none-any.whl (290 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.0/290.0 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.3.5)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.0.2)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.21.6)\n","Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (0.12.2)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.7.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2022.7)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (1.2.0)\n","Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels>=0.11.1->feature_engine) (0.5.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5->statsmodels>=0.11.1->feature_engine) (1.15.0)\n","Installing collected packages: feature_engine\n","Successfully installed feature_engine-1.5.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (2.7.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n","Installing collected packages: tensorflow_addons\n","Successfully installed tensorflow_addons-0.19.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting flake8\n","  Downloading flake8-6.0.0-py2.py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pycodestyle_magic\n","  Downloading pycodestyle_magic-0.5-py2.py3-none-any.whl (9.5 kB)\n","Collecting pycodestyle<2.11.0,>=2.10.0\n","  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mccabe<0.8.0,>=0.7.0\n","  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n","Collecting pyflakes<3.1.0,>=3.0.0\n","  Downloading pyflakes-3.0.1-py2.py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pycodestyle_magic, pyflakes, pycodestyle, mccabe, flake8\n","Successfully installed flake8-6.0.0 mccabe-0.7.0 pycodestyle-2.10.0 pycodestyle_magic-0.5 pyflakes-3.0.1\n"]}],"source":["!pip install feature_engine\n","!pip install tensorflow_addons\n","!pip install flake8 pycodestyle_magic"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18508,"status":"ok","timestamp":1673311713668,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"DlrWsVeJziRz","outputId":"d8598692-ca52-4dde-b4ed-42d275a13186"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["# for google colab\n","from google.colab import drive\n","# mount your Google Drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6699,"status":"ok","timestamp":1673311720362,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"lG_LL0PlzmFJ"},"outputs":[],"source":["# for google colab\n","# copy all files from \"HW5\" directory in Google drive to current directory\n","!cp -r ./gdrive/MyDrive/Final/* ."]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8880,"status":"ok","timestamp":1673311729235,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"oZBqBpJsznky"},"outputs":[],"source":["import os\n","import sys\n","import joblib\n","import numpy as np\n","import pandas as pd\n","import gc\n","from lightgbm import LGBMClassifier\n","from sklearn.impute import KNNImputer\n","from sklearn.metrics import roc_auc_score\n","from sklearn.naive_bayes import GaussianNB\n","from feature_engine.encoding import WoEEncoder\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.linear_model import LogisticRegression, HuberRegressor\n","from keras.models import load_model\n","from tensorflow.keras import Sequential\n","from tensorflow.keras import layers\n","from keras.models import load_model\n","from keras import backend as K\n","import warnings\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","warnings.filterwarnings(\"ignore\")\n","gc.enable()"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":634,"status":"ok","timestamp":1673311729850,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"MhE7A7lj2O0k"},"outputs":[],"source":["train = pd.read_csv('train.csv')\n","test = pd.read_csv('test.csv')\n","submission = pd.read_csv('sample_submission.csv')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1673311729851,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"PGo3xO0yzu26"},"outputs":[],"source":["# 1. fill the missing value\n","# (HuberRegressor + KNNImputer) 2. change attribute 0 to woe\n","def preprocessing(df_train, df_test):\n","    # record correlated relationship\n","    full_fill_dict = {}\n","    full_fill_dict['measurement_17'] = {\n","      'A': ['measurement_5', 'measurement_6', 'measurement_8'],\n","      'B': ['measurement_4', 'measurement_5', 'measurement_7'],\n","      'C': ['measurement_5', 'measurement_7', 'measurement_8',\n","            'measurement_9'],\n","      'D': ['measurement_5', 'measurement_6', 'measurement_7',\n","            'measurement_8'],\n","      'E': ['measurement_4', 'measurement_5', 'measurement_6',\n","            'measurement_8'],\n","      'F': ['measurement_4', 'measurement_5', 'measurement_6',\n","            'measurement_7'],\n","      'G': ['measurement_4', 'measurement_6', 'measurement_8',\n","            'measurement_9'],\n","      'H': ['measurement_4', 'measurement_5', 'measurement_7',\n","            'measurement_8', 'measurement_9'],\n","      'I': ['measurement_3', 'measurement_7', 'measurement_8']\n","    }\n","\n","    # data = train + test => take both train and test data into consideration\n","    data = pd.concat([df_train, df_test])\n","    # construct additional column to record the loss data for\n","    # measurement_3 & measurement_5 & area\n","    data['m3_missing'] = 1 * data['measurement_3'].isnull()\n","    data['m5_missing'] = 1 * data['measurement_5'].isnull()\n","    data['area'] = data['attribute_2'] * data['attribute_3']\n","\n","    # calculate the important order of all measurements which depends on\n","    # correlation filter out the column that has no relation to\n","    # measurement ramaining the related one and keep them in corelated_data\n","    # correlated_data = data[['measurement_' + str(i) for i in range(18)] +\n","    #          ['failure', 'area']]\n","    correlated_data_col = []\n","    for i in range(18):\n","        correlated_data_col.append('measurement_' + str(i))\n","    correlated_data_col.append('failure')\n","    correlated_data_col.append('area')\n","    correlated_data = data[correlated_data_col]\n","\n","    val = []\n","    col = []\n","    for x in range(3, 17):\n","        # data.corr()表示了data中的两个变量之间的相关性\n","        cor_val = correlated_data.corr()['measurement_' + str(x)]\n","        cor_val = np.absolute(cor_val)\n","        # get most 3 correlated value\n","        total_val = np.sum(cor_val.sort_values(ascending=False)[1:4])\n","        val.append(np.round(total_val, 3))\n","        col.append('measurement_' + str(x))\n","\n","    c = pd.DataFrame()\n","    c['corelated columns'] = col\n","    c['correlated value'] = val\n","    c = c.sort_values(\n","              by='correlated value',\n","              ascending=False).reset_index(drop=True)\n","\n","    # we just pick the most important 10 measurements\n","    # find the best corelated columns based on the product code\n","    # as the initial format of measurement17\n","    for i in range(10):\n","        # we select the next best correlated column since the\n","        # first one is initially set-up measurement17\n","        measurement_col = 'measurement_' + c.iloc[i, 0][12:]\n","        fill_dict = {}\n","        for x in data['product_code'].unique() : \n","            cor_val = correlated_data[data['product_code'] == x].corr()[measurement_col]\n","            cor_val = np.absolute(cor_val).sort_values(ascending=False)\n","            # keep the most important 4 measurement\n","            measurement_col_dic = {}\n","            measurement_col_dic[measurement_col] = cor_val[1:5].index.tolist()\n","            fill_dict[x] = measurement_col_dic[measurement_col]\n","        full_fill_dict[measurement_col] = fill_dict\n","\n","    # start running depends on product code\n","    for code in data['product_code'].unique():\n","        # use HuberRegressor to fill the missing value\n","        for measurement_col in list(full_fill_dict.keys()):\n","            # extract the current product code data\n","            tmp = data[data['product_code'] == code]\n","            # extract the correlated measurement we just claculated\n","            column = full_fill_dict[measurement_col][code]\n","            # collect all corelated measurement's data and drop rows which contain missing values\n","            tmp_train = tmp[column + [measurement_col]].dropna(how='any')\n","            # collect the data that doesn't miss data\n","            tmp_test = tmp[(tmp[column].isnull().sum(axis=1) == 0) & (tmp[measurement_col].isnull())]\n","            model = HuberRegressor(epsilon=1.9)\n","            model.fit(tmp_train[column], tmp_train[measurement_col])\n","            data.loc[\n","                (data['product_code'] == code) & (data[column].isnull().sum(axis=1) == 0) &\n","                (data[measurement_col].isnull()), measurement_col] = model.predict(tmp_test[column])\n","\n","        # use KNNImputer to fill the missing value\n","        # keep the column with loss data\n","        nullValue_cols = [col for col in df_train.columns if df_train[col].isnull().any()]\n","        # calculate the total missing data depends on each measurement and current product code\n","        NA = data.loc[data['product_code'] == code, nullValue_cols].isnull().sum().sum()\n","        # Imputation for completing missing values using k-Nearest Neighbors.\n","        model1 = KNNImputer(n_neighbors=3)\n","        feature = ['loading'] + ['measurement_' + str(i) for i in range(18)]\n","        data.loc[data['product_code'] == code, feature] = model1.fit_transform(data.loc[data['product_code'] == code, feature])\n","\n","    # measurement 3 - 16 looks like they belong to the same group\n","    data['measurement_avg'] = data[['measurement_' + str(i) for i in range(3, 17)]].mean(axis=1)\n","\n","    # replaces categories by the weight of evidence\n","    df_train = data.iloc[:len(df_train),:]\n","    df_test = data.iloc[len(df_train):,:]\n","    woe_encoder = WoEEncoder(variables=['attribute_0'])\n","    woe_encoder.fit(df_train, df_train['failure'])\n","    df_test = woe_encoder.transform(df_test)\n","  \n","    return df_test"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":18620,"status":"ok","timestamp":1673311748469,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"GlMFsQhe0ue6"},"outputs":[],"source":["df_test = preprocessing(train, test)\n","features = [\n","       'loading', 'attribute_0', 'measurement_17', 'measurement_0',\n","       'measurement_1', 'measurement_2', 'measurement_3', 'measurement_4',\n","       'measurement_5', 'measurement_6', 'measurement_7', 'measurement_8',\n","       'measurement_9', 'measurement_10', 'measurement_11', 'measurement_12',\n","       'measurement_13', 'measurement_14', 'measurement_15', 'measurement_16',\n","       'measurement_17',\n","       'area', 'm3_missing', 'm5_missing', 'measurement_avg']"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1673311748469,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"nNLMcF2h2HY7"},"outputs":[],"source":["X = ['A', 'B', 'C', 'D', 'E']\n","\n","folds_dict = {}\n","i = 1\n","for j in range(5):\n","    for k in range(j + 1, 5):\n","        tmp_X = X.copy()\n","        tmp_X.remove(X[j])\n","        tmp_X.remove(X[k])\n","        tmpList = list()\n","        tmpList.append(tmp_X)\n","        tmpList.append([X[j], X[k]])\n","        folds_dict['#' + str(i)] = tmpList\n","        i += 1"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47800,"status":"ok","timestamp":1673311796265,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"i3TKBJHe0wMD","outputId":"82094d9d-57e3-4e31-ca93-4cef2e2953d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["650/650 [==============================] - 5s 6ms/step\n","650/650 [==============================] - 4s 7ms/step\n","650/650 [==============================] - 5s 7ms/step\n","650/650 [==============================] - 4s 6ms/step\n","650/650 [==============================] - 4s 6ms/step\n","650/650 [==============================] - 4s 6ms/step\n","650/650 [==============================] - 4s 6ms/step\n","650/650 [==============================] - 4s 6ms/step\n","650/650 [==============================] - 4s 6ms/step\n","650/650 [==============================] - 4s 6ms/step\n"]}],"source":["model = load_model(\"model.h5\")\n","test_predictions = np.zeros((df_test.shape[0], 1))\n","\n","for fold in folds_dict.keys():\n","    test_pred = model.predict(df_test[features].values).reshape(-1, 1)\n","    test_predictions += test_pred / 10"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1673311796266,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"57Ob6INY0yho"},"outputs":[],"source":["submission['failure'] = test_predictions\n","submission.to_csv('submission.csv', index=False)\n","!cp submission.csv ./gdrive/MyDrive/Final/submission.csv"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"16847d31023ea665895a656bb61aa803bfcdc09ea951ca19f549021cdfa8d14f"}}},"nbformat":4,"nbformat_minor":0}
