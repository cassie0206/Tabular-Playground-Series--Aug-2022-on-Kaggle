{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18629,"status":"ok","timestamp":1673309881465,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"yE8LrdOyQ-IP","outputId":"95aa3dba-6b26-4e36-a83a-aa5c8dc3226d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting feature_engine\n","  Downloading feature_engine-1.5.2-py2.py3-none-any.whl (290 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.0/290.0 KB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (0.12.2)\n","Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.3.5)\n","Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.21.6)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.0.2)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.7.3)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2022.7)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2.8.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (3.1.0)\n","Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels>=0.11.1->feature_engine) (0.5.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5->statsmodels>=0.11.1->feature_engine) (1.15.0)\n","Installing collected packages: feature_engine\n","Successfully installed feature_engine-1.5.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (2.7.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n","Installing collected packages: tensorflow_addons\n","Successfully installed tensorflow_addons-0.19.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting flake8\n","  Downloading flake8-6.0.0-py2.py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pycodestyle_magic\n","  Downloading pycodestyle_magic-0.5-py2.py3-none-any.whl (9.5 kB)\n","Collecting mccabe<0.8.0,>=0.7.0\n","  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n","Collecting pycodestyle<2.11.0,>=2.10.0\n","  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyflakes<3.1.0,>=3.0.0\n","  Downloading pyflakes-3.0.1-py2.py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pycodestyle_magic, pyflakes, pycodestyle, mccabe, flake8\n","Successfully installed flake8-6.0.0 mccabe-0.7.0 pycodestyle-2.10.0 pycodestyle_magic-0.5 pyflakes-3.0.1\n"]}],"source":["!pip install feature_engine\n","!pip install tensorflow_addons\n","!pip install flake8 pycodestyle_magic"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":175961,"status":"ok","timestamp":1673310057420,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"Kvd7jbjvQ9dH","outputId":"011ae8fd-8658-450f-ee83-9ff1ebaef6e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# for google colab\n","from google.colab import drive\n","# mount your Google Drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5643,"status":"ok","timestamp":1673310063055,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"TihTN6_fQ-DU"},"outputs":[],"source":["# for google colab\n","# copy all files from \"HW5\" directory in Google drive to current directory\n","!cp -r ./gdrive/MyDrive/Final/* ."]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1673311248052,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"Dl7XF0P1RFG3"},"outputs":[],"source":["import os\n","import sys\n","import joblib\n","import numpy as np\n","import pandas as pd\n","import gc\n","from lightgbm import LGBMClassifier\n","from sklearn.impute import KNNImputer\n","from sklearn.metrics import roc_auc_score\n","from sklearn.naive_bayes import GaussianNB\n","from feature_engine.encoding import WoEEncoder\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.linear_model import LogisticRegression, HuberRegressor\n","from tensorflow.keras import Sequential\n","from tensorflow.keras import layers\n","from keras.models import Model\n","from keras.layers import Input, Dense, Dropout\n","from keras.layers import Flatten, Conv1D, MaxPooling1D, BatchNormalization\n","from keras import backend as K\n","import warnings\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","gc.enable()\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":446,"status":"ok","timestamp":1673310069268,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"ENTvNWSlRHe5"},"outputs":[],"source":["train = pd.read_csv('train.csv')\n","test = pd.read_csv('test.csv')\n","submission = pd.read_csv('sample_submission.csv')\n","tf.random.set_seed(42)"]},{"cell_type":"markdown","metadata":{"id":"bSPISNgeZK9S"},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":12635,"status":"ok","timestamp":1673311361867,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"EGCSK708RPux"},"outputs":[],"source":["def preprocessing(df_train, df_test):\n","    # record correlated relationship\n","    full_fill_dict = {}\n","    full_fill_dict['measurement_17'] = {\n","      'A': ['measurement_5', 'measurement_6', 'measurement_8'],\n","      'B': ['measurement_4', 'measurement_5', 'measurement_7'],\n","      'C': ['measurement_5', 'measurement_7', 'measurement_8',\n","            'measurement_9'],\n","      'D': ['measurement_5', 'measurement_6', 'measurement_7',\n","            'measurement_8'],\n","      'E': ['measurement_4', 'measurement_5', 'measurement_6',\n","            'measurement_8'],\n","      'F': ['measurement_4', 'measurement_5', 'measurement_6',\n","            'measurement_7'],\n","      'G': ['measurement_4', 'measurement_6', 'measurement_8',\n","            'measurement_9'],\n","      'H': ['measurement_4', 'measurement_5', 'measurement_7',\n","            'measurement_8', 'measurement_9'],\n","      'I': ['measurement_3', 'measurement_7', 'measurement_8']\n","    }\n","\n","    # data = train + test => take both train and test data into consideration\n","    data = pd.concat([df_train, df_test])\n","    # construct additional column to record the loss data for\n","    # measurement_3 & measurement_5 & area\n","    data['m3_missing'] = 1 * data['measurement_3'].isnull()\n","    data['m5_missing'] = 1 * data['measurement_5'].isnull()\n","    data['area'] = data['attribute_2'] * data['attribute_3']\n","\n","    # calculate the important order of all measurements which depends on\n","    # correlation filter out the column that has no relation to\n","    # measurement ramaining the related one and keep them in corelated_data\n","    # correlated_data = data[['measurement_' + str(i) for i in range(18)] +\n","    #          ['failure', 'area']]\n","    correlated_data_col = []\n","    for i in range(18):\n","        correlated_data_col.append('measurement_' + str(i))\n","    correlated_data_col.append('failure')\n","    correlated_data_col.append('area')\n","    correlated_data = data[correlated_data_col]\n","\n","    val = []\n","    col = []\n","    for x in range(3, 17):\n","        # data.corr()表示了data中的两个变量之间的相关性\n","        cor_val = correlated_data.corr()['measurement_' + str(x)]\n","        cor_val = np.absolute(cor_val)\n","        # get most 3 correlated value\n","        total_val = np.sum(cor_val.sort_values(ascending=False)[1:4])\n","        val.append(np.round(total_val, 3))\n","        col.append('measurement_' + str(x))\n","\n","    c = pd.DataFrame()\n","    c['corelated columns'] = col\n","    c['correlated value'] = val\n","    c = c.sort_values(\n","              by='correlated value',\n","              ascending=False).reset_index(drop=True)\n","\n","    # we just pick the most important 10 measurements\n","    # find the best corelated columns based on the product code\n","    # as the initial format of measurement17\n","    for i in range(10):\n","        # we select the next best correlated column since the\n","        # first one is initially set-up measurement17\n","        measurement_col = 'measurement_' + c.iloc[i, 0][12:]\n","        fill_dict = {}\n","        for x in data['product_code'].unique() : \n","            cor_val = correlated_data[data['product_code'] == x].corr()[measurement_col]\n","            cor_val = np.absolute(cor_val).sort_values(ascending=False)\n","            # keep the most important 4 measurement\n","            measurement_col_dic = {}\n","            measurement_col_dic[measurement_col] = cor_val[1:5].index.tolist()\n","            fill_dict[x] = measurement_col_dic[measurement_col]\n","        full_fill_dict[measurement_col] = fill_dict\n","\n","    # start running depends on product code\n","    for code in data['product_code'].unique():\n","        # use HuberRegressor to fill the missing value\n","        for measurement_col in list(full_fill_dict.keys()):\n","            # extract the current product code data\n","            tmp = data[data['product_code'] == code]\n","            # extract the correlated measurement we just claculated\n","            column = full_fill_dict[measurement_col][code]\n","            # collect all corelated measurement's data and drop rows which contain missing values\n","            tmp_train = tmp[column + [measurement_col]].dropna(how='any')\n","            # collect the data that doesn't miss data\n","            tmp_test = tmp[(tmp[column].isnull().sum(axis=1) == 0) & (tmp[measurement_col].isnull())]\n","            model = HuberRegressor(epsilon=1.9)\n","            model.fit(tmp_train[column], tmp_train[measurement_col])\n","            data.loc[\n","                (data['product_code'] == code) & (data[column].isnull().sum(axis=1) == 0) &\n","                (data[measurement_col].isnull()), measurement_col] = model.predict(tmp_test[column])\n","\n","        # use KNNImputer to fill the missing value\n","        # keep the column with loss data\n","        nullValue_cols = [col for col in df_train.columns if df_train[col].isnull().any()]\n","        # calculate the total missing data depends on each measurement and current product code\n","        NA = data.loc[data['product_code'] == code, nullValue_cols].isnull().sum().sum()\n","        # Imputation for completing missing values using k-Nearest Neighbors.\n","        model1 = KNNImputer(n_neighbors=3)\n","        feature = ['loading'] + ['measurement_' + str(i) for i in range(18)]\n","        data.loc[data['product_code'] == code, feature] = model1.fit_transform(data.loc[data['product_code'] == code, feature])\n","\n","    # measurement 3 - 16 looks like they belong to the same group\n","    data['measurement_avg'] = data[['measurement_' + str(i) for i in range(3, 17)]].mean(axis=1)\n","\n","    # replaces categories by the weight of evidence\n","    df_train = data.iloc[:len(df_train), :]\n","    woe_encoder = WoEEncoder(variables=['attribute_0'])\n","    woe_encoder.fit(df_train, df_train['failure'])\n","    df_train = woe_encoder.transform(df_train)\n","\n","    return df_train\n","\n","df_train = preprocessing(train, test)"]},{"cell_type":"markdown","metadata":{"id":"aIN6KVOGZTJh"},"source":["# Build Model"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1673310085115,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"-DIz2Tur33r_"},"outputs":[],"source":["def build_model(total_col):\n","    model = Sequential()\n","    model.add(Conv1D(\n","             filters=32, kernel_size=3, padding='same',\n","             activation='relu', input_shape=(25, 1)))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(pool_size=2, padding='same'))\n","    model.add(Dropout(0.2))\n","    model.add(Conv1D(\n","             filters=64, kernel_size=3,\n","             padding='same', activation='relu'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(pool_size=2, padding='same'))\n","    model.add(Dropout(0.2))\n","    model.add(Conv1D(\n","             filters=128, kernel_size=3,\n","             padding='same', activation='relu'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(pool_size=2, padding='same'))\n","    model.add(Dropout(0.2))\n","    model.add(Conv1D(\n","             filters=256, kernel_size=3,\n","             padding='same', activation='relu'))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling1D(pool_size=2, padding='same'))\n","    model.add(Flatten())\n","    model.add(Dropout(0.2))\n","    model.add(Dense(units=1, activation='sigmoid'))\n","\n","    return model"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1673310085115,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"aXghO39aRTzp"},"outputs":[],"source":["features = [\n","       'loading', 'attribute_0', 'measurement_17', 'measurement_0',\n","       'measurement_1', 'measurement_2', 'measurement_3', 'measurement_4',\n","       'measurement_5', 'measurement_6', 'measurement_7', 'measurement_8',\n","       'measurement_9', 'measurement_10', 'measurement_11', 'measurement_12',\n","       'measurement_13', 'measurement_14', 'measurement_15', 'measurement_16',\n","       'measurement_17',\n","       'area', 'm3_missing', 'm5_missing', 'measurement_avg']"]},{"cell_type":"markdown","metadata":{"id":"o0OdEHiPZDGB"},"source":["# Cross Validation"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1673310085116,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"bx-4O-EfRLxe"},"outputs":[],"source":["X = ['A', 'B', 'C', 'D', 'E']\n","\n","folds_dict = {}\n","i = 1\n","for j in range(5):\n","    for k in range(j + 1, 5):\n","        tmp_X = X.copy()\n","        tmp_X.remove(X[j])\n","        tmp_X.remove(X[k])\n","        tmpList = list()\n","        tmpList.append(tmp_X)\n","        tmpList.append([X[j], X[k]])\n","        folds_dict['#' + str(i)] = tmpList\n","        i += 1"]},{"cell_type":"markdown","metadata":{"id":"4B0ehYHdYW5E"},"source":["# Training"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":844385,"status":"ok","timestamp":1673310929494,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"NWxAJN-dRXe1","outputId":"567c7e3b-af84-4a08-f4db-70ca203474d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["fold #1\n","Epoch 1/200\n","254/254 [==============================] - 13s 12ms/step - loss: 0.6040 - auc: 0.5037 - val_loss: 0.5213 - val_auc: 0.5246 - lr: 0.0010\n","Epoch 2/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5267 - auc: 0.5183 - val_loss: 0.5162 - val_auc: 0.5792 - lr: 0.0010\n","Epoch 3/200\n","254/254 [==============================] - 2s 10ms/step - loss: 0.5172 - auc: 0.5427 - val_loss: 0.5161 - val_auc: 0.5575 - lr: 0.0010\n","Epoch 4/200\n","254/254 [==============================] - 3s 11ms/step - loss: 0.5175 - auc: 0.5343 - val_loss: 0.5188 - val_auc: 0.5841 - lr: 0.0010\n","Epoch 5/200\n","254/254 [==============================] - 2s 10ms/step - loss: 0.5142 - auc: 0.5540 - val_loss: 0.5151 - val_auc: 0.5804 - lr: 0.0010\n","Epoch 6/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5150 - auc: 0.5448 - val_loss: 0.5164 - val_auc: 0.5864 - lr: 0.0010\n","Epoch 7/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5136 - auc: 0.5538 - val_loss: 0.5147 - val_auc: 0.5898 - lr: 0.0010\n","Epoch 8/200\n","254/254 [==============================] - 2s 10ms/step - loss: 0.5130 - auc: 0.5580 - val_loss: 0.5154 - val_auc: 0.5848 - lr: 0.0010\n","Epoch 9/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5124 - auc: 0.5634 - val_loss: 0.5106 - val_auc: 0.5918 - lr: 0.0010\n","Epoch 10/200\n","254/254 [==============================] - 2s 10ms/step - loss: 0.5127 - auc: 0.5600 - val_loss: 0.5211 - val_auc: 0.5800 - lr: 0.0010\n","Epoch 11/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5132 - auc: 0.5574 - val_loss: 0.5144 - val_auc: 0.5888 - lr: 0.0010\n","Epoch 12/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5134 - auc: 0.5570 - val_loss: 0.5129 - val_auc: 0.5914 - lr: 0.0010\n","Epoch 13/200\n","254/254 [==============================] - 2s 10ms/step - loss: 0.5126 - auc: 0.5639 - val_loss: 0.5168 - val_auc: 0.5837 - lr: 0.0010\n","Epoch 14/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5129 - auc: 0.5558 - val_loss: 0.5152 - val_auc: 0.5918 - lr: 0.0010\n","Epoch 15/200\n","254/254 [==============================] - 2s 10ms/step - loss: 0.5127 - auc: 0.5609 - val_loss: 0.5150 - val_auc: 0.5902 - lr: 0.0010\n","Epoch 16/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5130 - auc: 0.5594 - val_loss: 0.5128 - val_auc: 0.5896 - lr: 0.0010\n","Epoch 17/200\n","254/254 [==============================] - 3s 12ms/step - loss: 0.5133 - auc: 0.5550 - val_loss: 0.5141 - val_auc: 0.5897 - lr: 0.0010\n","Epoch 18/200\n","254/254 [==============================] - 3s 11ms/step - loss: 0.5126 - auc: 0.5620 - val_loss: 0.5138 - val_auc: 0.5889 - lr: 0.0010\n","Epoch 19/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5118 - auc: 0.5663 - val_loss: 0.5176 - val_auc: 0.5893 - lr: 9.0000e-04\n","fold #2\n","Epoch 1/200\n","246/246 [==============================] - 5s 12ms/step - loss: 0.6044 - auc: 0.4946 - val_loss: 0.5326 - val_auc: 0.4968 - lr: 0.0010\n","Epoch 2/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5229 - auc: 0.5177 - val_loss: 0.5243 - val_auc: 0.5522 - lr: 0.0010\n","Epoch 3/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5156 - auc: 0.5211 - val_loss: 0.5234 - val_auc: 0.5667 - lr: 0.0010\n","Epoch 4/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5116 - auc: 0.5436 - val_loss: 0.5239 - val_auc: 0.5777 - lr: 0.0010\n","Epoch 5/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5108 - auc: 0.5416 - val_loss: 0.5235 - val_auc: 0.5660 - lr: 0.0010\n","Epoch 6/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5085 - auc: 0.5566 - val_loss: 0.5230 - val_auc: 0.5697 - lr: 0.0010\n","Epoch 7/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5098 - auc: 0.5483 - val_loss: 0.5206 - val_auc: 0.5845 - lr: 0.0010\n","Epoch 8/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5091 - auc: 0.5506 - val_loss: 0.5219 - val_auc: 0.5831 - lr: 0.0010\n","Epoch 9/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5086 - auc: 0.5546 - val_loss: 0.5255 - val_auc: 0.5844 - lr: 0.0010\n","Epoch 10/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5082 - auc: 0.5570 - val_loss: 0.5212 - val_auc: 0.5884 - lr: 0.0010\n","Epoch 11/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5087 - auc: 0.5562 - val_loss: 0.5234 - val_auc: 0.5808 - lr: 0.0010\n","Epoch 12/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5081 - auc: 0.5607 - val_loss: 0.5186 - val_auc: 0.5896 - lr: 0.0010\n","Epoch 13/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5072 - auc: 0.5662 - val_loss: 0.5323 - val_auc: 0.5778 - lr: 0.0010\n","Epoch 14/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5069 - auc: 0.5678 - val_loss: 0.5228 - val_auc: 0.5896 - lr: 0.0010\n","Epoch 15/200\n","246/246 [==============================] - 3s 11ms/step - loss: 0.5084 - auc: 0.5542 - val_loss: 0.5226 - val_auc: 0.5857 - lr: 0.0010\n","Epoch 16/200\n","246/246 [==============================] - 3s 11ms/step - loss: 0.5078 - auc: 0.5610 - val_loss: 0.5191 - val_auc: 0.5883 - lr: 0.0010\n","Epoch 17/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5080 - auc: 0.5584 - val_loss: 0.5201 - val_auc: 0.5891 - lr: 0.0010\n","Epoch 18/200\n","246/246 [==============================] - 3s 11ms/step - loss: 0.5063 - auc: 0.5718 - val_loss: 0.5222 - val_auc: 0.5856 - lr: 0.0010\n","Epoch 19/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5076 - auc: 0.5617 - val_loss: 0.5219 - val_auc: 0.5826 - lr: 0.0010\n","Epoch 20/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5080 - auc: 0.5580 - val_loss: 0.5403 - val_auc: 0.5875 - lr: 0.0010\n","Epoch 21/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5077 - auc: 0.5631 - val_loss: 0.5279 - val_auc: 0.5855 - lr: 0.0010\n","Epoch 22/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5079 - auc: 0.5614 - val_loss: 0.5241 - val_auc: 0.5869 - lr: 0.0010\n","fold #3\n","Epoch 1/200\n","256/256 [==============================] - 5s 12ms/step - loss: 0.5951 - auc: 0.4992 - val_loss: 0.5369 - val_auc: 0.4888 - lr: 0.0010\n","Epoch 2/200\n","256/256 [==============================] - 3s 10ms/step - loss: 0.5245 - auc: 0.5016 - val_loss: 0.5302 - val_auc: 0.5126 - lr: 0.0010\n","Epoch 3/200\n","256/256 [==============================] - 3s 11ms/step - loss: 0.5140 - auc: 0.5041 - val_loss: 0.5310 - val_auc: 0.5594 - lr: 0.0010\n","Epoch 4/200\n","256/256 [==============================] - 3s 10ms/step - loss: 0.5098 - auc: 0.5348 - val_loss: 0.5297 - val_auc: 0.5246 - lr: 0.0010\n","Epoch 5/200\n","256/256 [==============================] - 3s 10ms/step - loss: 0.5088 - auc: 0.5384 - val_loss: 0.5286 - val_auc: 0.5793 - lr: 0.0010\n","Epoch 6/200\n","256/256 [==============================] - 3s 11ms/step - loss: 0.5079 - auc: 0.5437 - val_loss: 0.5294 - val_auc: 0.5801 - lr: 0.0010\n","Epoch 7/200\n","256/256 [==============================] - 3s 11ms/step - loss: 0.5067 - auc: 0.5531 - val_loss: 0.5309 - val_auc: 0.5885 - lr: 0.0010\n","Epoch 8/200\n","256/256 [==============================] - 3s 11ms/step - loss: 0.5073 - auc: 0.5468 - val_loss: 0.5278 - val_auc: 0.5848 - lr: 0.0010\n","Epoch 9/200\n","256/256 [==============================] - 3s 11ms/step - loss: 0.5069 - auc: 0.5506 - val_loss: 0.5328 - val_auc: 0.5782 - lr: 0.0010\n","Epoch 10/200\n","256/256 [==============================] - 3s 10ms/step - loss: 0.5061 - auc: 0.5579 - val_loss: 0.5356 - val_auc: 0.5814 - lr: 0.0010\n","Epoch 11/200\n","256/256 [==============================] - 3s 10ms/step - loss: 0.5060 - auc: 0.5554 - val_loss: 0.5236 - val_auc: 0.5938 - lr: 0.0010\n","Epoch 12/200\n","256/256 [==============================] - 3s 10ms/step - loss: 0.5065 - auc: 0.5532 - val_loss: 0.5237 - val_auc: 0.5941 - lr: 0.0010\n","Epoch 13/200\n","256/256 [==============================] - 3s 10ms/step - loss: 0.5061 - auc: 0.5547 - val_loss: 0.5257 - val_auc: 0.5954 - lr: 0.0010\n","Epoch 14/200\n","256/256 [==============================] - 3s 10ms/step - loss: 0.5062 - auc: 0.5561 - val_loss: 0.5317 - val_auc: 0.5907 - lr: 0.0010\n","Epoch 15/200\n","256/256 [==============================] - 3s 10ms/step - loss: 0.5057 - auc: 0.5596 - val_loss: 0.5238 - val_auc: 0.5932 - lr: 0.0010\n","Epoch 16/200\n","256/256 [==============================] - 3s 10ms/step - loss: 0.5056 - auc: 0.5631 - val_loss: 0.5257 - val_auc: 0.5956 - lr: 0.0010\n","Epoch 17/200\n","256/256 [==============================] - 3s 11ms/step - loss: 0.5067 - auc: 0.5511 - val_loss: 0.5260 - val_auc: 0.5942 - lr: 0.0010\n","Epoch 18/200\n","256/256 [==============================] - 3s 10ms/step - loss: 0.5064 - auc: 0.5537 - val_loss: 0.5249 - val_auc: 0.5955 - lr: 0.0010\n","Epoch 19/200\n","256/256 [==============================] - 3s 10ms/step - loss: 0.5052 - auc: 0.5662 - val_loss: 0.5241 - val_auc: 0.5931 - lr: 0.0010\n","Epoch 20/200\n","256/256 [==============================] - 3s 10ms/step - loss: 0.5063 - auc: 0.5541 - val_loss: 0.5272 - val_auc: 0.5936 - lr: 0.0010\n","Epoch 21/200\n","256/256 [==============================] - 3s 10ms/step - loss: 0.5063 - auc: 0.5553 - val_loss: 0.5249 - val_auc: 0.5900 - lr: 0.0010\n","fold #4\n","Epoch 1/200\n","252/252 [==============================] - 5s 12ms/step - loss: 0.5958 - auc: 0.5074 - val_loss: 0.5233 - val_auc: 0.5663 - lr: 0.0010\n","Epoch 2/200\n","252/252 [==============================] - 2s 10ms/step - loss: 0.5266 - auc: 0.5132 - val_loss: 0.5234 - val_auc: 0.5501 - lr: 0.0010\n","Epoch 3/200\n","252/252 [==============================] - 3s 11ms/step - loss: 0.5163 - auc: 0.5288 - val_loss: 0.5215 - val_auc: 0.5609 - lr: 0.0010\n","Epoch 4/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5138 - auc: 0.5386 - val_loss: 0.5206 - val_auc: 0.5743 - lr: 0.0010\n","Epoch 5/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5121 - auc: 0.5507 - val_loss: 0.5201 - val_auc: 0.5774 - lr: 0.0010\n","Epoch 6/200\n","252/252 [==============================] - 2s 10ms/step - loss: 0.5120 - auc: 0.5475 - val_loss: 0.5219 - val_auc: 0.5702 - lr: 0.0010\n","Epoch 7/200\n","252/252 [==============================] - 2s 10ms/step - loss: 0.5106 - auc: 0.5581 - val_loss: 0.5225 - val_auc: 0.5815 - lr: 0.0010\n","Epoch 8/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5106 - auc: 0.5560 - val_loss: 0.5235 - val_auc: 0.5815 - lr: 0.0010\n","Epoch 9/200\n","252/252 [==============================] - 2s 10ms/step - loss: 0.5102 - auc: 0.5595 - val_loss: 0.5429 - val_auc: 0.5790 - lr: 0.0010\n","Epoch 10/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5108 - auc: 0.5545 - val_loss: 0.5185 - val_auc: 0.5858 - lr: 0.0010\n","Epoch 11/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5100 - auc: 0.5603 - val_loss: 0.5231 - val_auc: 0.5758 - lr: 0.0010\n","Epoch 12/200\n","252/252 [==============================] - 3s 11ms/step - loss: 0.5099 - auc: 0.5608 - val_loss: 0.5202 - val_auc: 0.5730 - lr: 0.0010\n","Epoch 13/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5103 - auc: 0.5547 - val_loss: 0.5185 - val_auc: 0.5843 - lr: 0.0010\n","Epoch 14/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5105 - auc: 0.5555 - val_loss: 0.5214 - val_auc: 0.5584 - lr: 0.0010\n","Epoch 15/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5103 - auc: 0.5577 - val_loss: 0.5175 - val_auc: 0.5882 - lr: 0.0010\n","Epoch 16/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5091 - auc: 0.5649 - val_loss: 0.5176 - val_auc: 0.5876 - lr: 0.0010\n","Epoch 17/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5094 - auc: 0.5647 - val_loss: 0.5170 - val_auc: 0.5883 - lr: 0.0010\n","Epoch 18/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5098 - auc: 0.5599 - val_loss: 0.5223 - val_auc: 0.5852 - lr: 0.0010\n","Epoch 19/200\n","252/252 [==============================] - 3s 11ms/step - loss: 0.5106 - auc: 0.5562 - val_loss: 0.5172 - val_auc: 0.5867 - lr: 0.0010\n","Epoch 20/200\n","252/252 [==============================] - 2s 10ms/step - loss: 0.5099 - auc: 0.5599 - val_loss: 0.5167 - val_auc: 0.5881 - lr: 0.0010\n","Epoch 21/200\n","252/252 [==============================] - 3s 11ms/step - loss: 0.5092 - auc: 0.5651 - val_loss: 0.5169 - val_auc: 0.5884 - lr: 0.0010\n","Epoch 22/200\n","252/252 [==============================] - 3s 11ms/step - loss: 0.5092 - auc: 0.5643 - val_loss: 0.5222 - val_auc: 0.5851 - lr: 0.0010\n","Epoch 23/200\n","252/252 [==============================] - 2s 10ms/step - loss: 0.5097 - auc: 0.5602 - val_loss: 0.5165 - val_auc: 0.5874 - lr: 0.0010\n","Epoch 24/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5088 - auc: 0.5688 - val_loss: 0.5169 - val_auc: 0.5871 - lr: 0.0010\n","Epoch 25/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5090 - auc: 0.5675 - val_loss: 0.5155 - val_auc: 0.5885 - lr: 0.0010\n","Epoch 26/200\n","252/252 [==============================] - 2s 10ms/step - loss: 0.5089 - auc: 0.5669 - val_loss: 0.5207 - val_auc: 0.5879 - lr: 0.0010\n","Epoch 27/200\n","252/252 [==============================] - 2s 10ms/step - loss: 0.5097 - auc: 0.5635 - val_loss: 0.5160 - val_auc: 0.5875 - lr: 0.0010\n","Epoch 28/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5098 - auc: 0.5603 - val_loss: 0.5259 - val_auc: 0.5818 - lr: 0.0010\n","Epoch 29/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5088 - auc: 0.5683 - val_loss: 0.5269 - val_auc: 0.5746 - lr: 0.0010\n","Epoch 30/200\n","252/252 [==============================] - 2s 10ms/step - loss: 0.5082 - auc: 0.5725 - val_loss: 0.5201 - val_auc: 0.5731 - lr: 9.0000e-04\n","Epoch 31/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5080 - auc: 0.5722 - val_loss: 0.5188 - val_auc: 0.5885 - lr: 9.0000e-04\n","Epoch 32/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5087 - auc: 0.5691 - val_loss: 0.5227 - val_auc: 0.5852 - lr: 9.0000e-04\n","Epoch 33/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5094 - auc: 0.5644 - val_loss: 0.5203 - val_auc: 0.5837 - lr: 9.0000e-04\n","Epoch 34/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5100 - auc: 0.5613 - val_loss: 0.5397 - val_auc: 0.5861 - lr: 9.0000e-04\n","Epoch 35/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5094 - auc: 0.5623 - val_loss: 0.5156 - val_auc: 0.5877 - lr: 9.0000e-04\n","fold #5\n","Epoch 1/200\n","244/244 [==============================] - 5s 12ms/step - loss: 0.6116 - auc: 0.4975 - val_loss: 0.5229 - val_auc: 0.5066 - lr: 0.0010\n","Epoch 2/200\n","244/244 [==============================] - 2s 10ms/step - loss: 0.5384 - auc: 0.5021 - val_loss: 0.5100 - val_auc: 0.5388 - lr: 0.0010\n","Epoch 3/200\n","244/244 [==============================] - 3s 11ms/step - loss: 0.5285 - auc: 0.5083 - val_loss: 0.5108 - val_auc: 0.5658 - lr: 0.0010\n","Epoch 4/200\n","244/244 [==============================] - 3s 10ms/step - loss: 0.5230 - auc: 0.5376 - val_loss: 0.5098 - val_auc: 0.5449 - lr: 0.0010\n","Epoch 5/200\n","244/244 [==============================] - 2s 10ms/step - loss: 0.5209 - auc: 0.5537 - val_loss: 0.5187 - val_auc: 0.5852 - lr: 0.0010\n","Epoch 6/200\n","244/244 [==============================] - 2s 10ms/step - loss: 0.5217 - auc: 0.5456 - val_loss: 0.5067 - val_auc: 0.5782 - lr: 0.0010\n","Epoch 7/200\n","244/244 [==============================] - 3s 10ms/step - loss: 0.5212 - auc: 0.5480 - val_loss: 0.5055 - val_auc: 0.5760 - lr: 0.0010\n","Epoch 8/200\n","244/244 [==============================] - 3s 11ms/step - loss: 0.5203 - auc: 0.5559 - val_loss: 0.5059 - val_auc: 0.5796 - lr: 0.0010\n","Epoch 9/200\n","244/244 [==============================] - 3s 11ms/step - loss: 0.5192 - auc: 0.5634 - val_loss: 0.5049 - val_auc: 0.5835 - lr: 0.0010\n","Epoch 10/200\n","244/244 [==============================] - 2s 10ms/step - loss: 0.5211 - auc: 0.5476 - val_loss: 0.5135 - val_auc: 0.5845 - lr: 0.0010\n","Epoch 11/200\n","244/244 [==============================] - 2s 10ms/step - loss: 0.5197 - auc: 0.5594 - val_loss: 0.5107 - val_auc: 0.5691 - lr: 0.0010\n","Epoch 12/200\n","244/244 [==============================] - 2s 10ms/step - loss: 0.5191 - auc: 0.5636 - val_loss: 0.5035 - val_auc: 0.5873 - lr: 0.0010\n","Epoch 13/200\n","244/244 [==============================] - 2s 10ms/step - loss: 0.5191 - auc: 0.5642 - val_loss: 0.5191 - val_auc: 0.5841 - lr: 0.0010\n","Epoch 14/200\n","244/244 [==============================] - 3s 11ms/step - loss: 0.5192 - auc: 0.5639 - val_loss: 0.5095 - val_auc: 0.5867 - lr: 0.0010\n","Epoch 15/200\n","244/244 [==============================] - 2s 10ms/step - loss: 0.5195 - auc: 0.5614 - val_loss: 0.5038 - val_auc: 0.5850 - lr: 0.0010\n","Epoch 16/200\n","244/244 [==============================] - 2s 10ms/step - loss: 0.5190 - auc: 0.5638 - val_loss: 0.5063 - val_auc: 0.5721 - lr: 0.0010\n","Epoch 17/200\n","244/244 [==============================] - 3s 11ms/step - loss: 0.5187 - auc: 0.5637 - val_loss: 0.5040 - val_auc: 0.5877 - lr: 0.0010\n","Epoch 18/200\n","244/244 [==============================] - 3s 11ms/step - loss: 0.5196 - auc: 0.5597 - val_loss: 0.5030 - val_auc: 0.5868 - lr: 0.0010\n","Epoch 19/200\n","244/244 [==============================] - 3s 11ms/step - loss: 0.5187 - auc: 0.5645 - val_loss: 0.5016 - val_auc: 0.5854 - lr: 9.0000e-04\n","Epoch 20/200\n","244/244 [==============================] - 3s 11ms/step - loss: 0.5181 - auc: 0.5672 - val_loss: 0.5221 - val_auc: 0.5880 - lr: 9.0000e-04\n","Epoch 21/200\n","244/244 [==============================] - 2s 10ms/step - loss: 0.5196 - auc: 0.5601 - val_loss: 0.5030 - val_auc: 0.5874 - lr: 9.0000e-04\n","Epoch 22/200\n","244/244 [==============================] - 2s 10ms/step - loss: 0.5189 - auc: 0.5623 - val_loss: 0.5200 - val_auc: 0.5775 - lr: 9.0000e-04\n","Epoch 23/200\n","244/244 [==============================] - 2s 10ms/step - loss: 0.5182 - auc: 0.5687 - val_loss: 0.5048 - val_auc: 0.5853 - lr: 9.0000e-04\n","Epoch 24/200\n","244/244 [==============================] - 3s 11ms/step - loss: 0.5187 - auc: 0.5675 - val_loss: 0.5023 - val_auc: 0.5868 - lr: 9.0000e-04\n","Epoch 25/200\n","244/244 [==============================] - 3s 11ms/step - loss: 0.5183 - auc: 0.5670 - val_loss: 0.5021 - val_auc: 0.5876 - lr: 9.0000e-04\n","Epoch 26/200\n","244/244 [==============================] - 2s 10ms/step - loss: 0.5184 - auc: 0.5699 - val_loss: 0.5027 - val_auc: 0.5852 - lr: 9.0000e-04\n","Epoch 27/200\n","244/244 [==============================] - 3s 11ms/step - loss: 0.5186 - auc: 0.5652 - val_loss: 0.5061 - val_auc: 0.5855 - lr: 9.0000e-04\n","Epoch 28/200\n","244/244 [==============================] - 3s 10ms/step - loss: 0.5184 - auc: 0.5683 - val_loss: 0.5115 - val_auc: 0.5871 - lr: 9.0000e-04\n","Epoch 29/200\n","244/244 [==============================] - 3s 11ms/step - loss: 0.5188 - auc: 0.5648 - val_loss: 0.5151 - val_auc: 0.5877 - lr: 9.0000e-04\n","fold #6\n","Epoch 1/200\n","254/254 [==============================] - 5s 12ms/step - loss: 0.5990 - auc: 0.4989 - val_loss: 0.5310 - val_auc: 0.4860 - lr: 0.0010\n","Epoch 2/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5322 - auc: 0.5096 - val_loss: 0.5115 - val_auc: 0.5466 - lr: 0.0010\n","Epoch 3/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5246 - auc: 0.5244 - val_loss: 0.5118 - val_auc: 0.5804 - lr: 0.0010\n","Epoch 4/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5208 - auc: 0.5381 - val_loss: 0.5112 - val_auc: 0.5754 - lr: 0.0010\n","Epoch 5/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5195 - auc: 0.5395 - val_loss: 0.5151 - val_auc: 0.5763 - lr: 0.0010\n","Epoch 6/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5184 - auc: 0.5505 - val_loss: 0.5110 - val_auc: 0.5881 - lr: 0.0010\n","Epoch 7/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5174 - auc: 0.5555 - val_loss: 0.5081 - val_auc: 0.5936 - lr: 0.0010\n","Epoch 8/200\n","254/254 [==============================] - 3s 11ms/step - loss: 0.5172 - auc: 0.5583 - val_loss: 0.5107 - val_auc: 0.5914 - lr: 0.0010\n","Epoch 9/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5186 - auc: 0.5456 - val_loss: 0.5083 - val_auc: 0.5867 - lr: 0.0010\n","Epoch 10/200\n","254/254 [==============================] - 3s 13ms/step - loss: 0.5176 - auc: 0.5536 - val_loss: 0.5069 - val_auc: 0.5853 - lr: 0.0010\n","Epoch 11/200\n","254/254 [==============================] - 3s 12ms/step - loss: 0.5170 - auc: 0.5594 - val_loss: 0.5121 - val_auc: 0.5926 - lr: 0.0010\n","Epoch 12/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5168 - auc: 0.5603 - val_loss: 0.5104 - val_auc: 0.5947 - lr: 0.0010\n","Epoch 13/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5166 - auc: 0.5620 - val_loss: 0.5079 - val_auc: 0.5847 - lr: 0.0010\n","Epoch 14/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5174 - auc: 0.5530 - val_loss: 0.5092 - val_auc: 0.5950 - lr: 0.0010\n","Epoch 15/200\n","254/254 [==============================] - 3s 11ms/step - loss: 0.5175 - auc: 0.5516 - val_loss: 0.5094 - val_auc: 0.5922 - lr: 0.0010\n","Epoch 16/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5163 - auc: 0.5624 - val_loss: 0.5067 - val_auc: 0.5888 - lr: 0.0010\n","Epoch 17/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5167 - auc: 0.5621 - val_loss: 0.5149 - val_auc: 0.5938 - lr: 0.0010\n","Epoch 18/200\n","254/254 [==============================] - 3s 11ms/step - loss: 0.5170 - auc: 0.5587 - val_loss: 0.5105 - val_auc: 0.5925 - lr: 0.0010\n","Epoch 19/200\n","254/254 [==============================] - 3s 11ms/step - loss: 0.5167 - auc: 0.5605 - val_loss: 0.5108 - val_auc: 0.5899 - lr: 0.0010\n","Epoch 20/200\n","254/254 [==============================] - 3s 11ms/step - loss: 0.5159 - auc: 0.5652 - val_loss: 0.5158 - val_auc: 0.5848 - lr: 0.0010\n","Epoch 21/200\n","254/254 [==============================] - 3s 11ms/step - loss: 0.5166 - auc: 0.5617 - val_loss: 0.5176 - val_auc: 0.5814 - lr: 0.0010\n","Epoch 22/200\n","254/254 [==============================] - 3s 11ms/step - loss: 0.5181 - auc: 0.5486 - val_loss: 0.5101 - val_auc: 0.5901 - lr: 0.0010\n","Epoch 23/200\n","254/254 [==============================] - 3s 11ms/step - loss: 0.5170 - auc: 0.5563 - val_loss: 0.5117 - val_auc: 0.5852 - lr: 0.0010\n","Epoch 24/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5171 - auc: 0.5531 - val_loss: 0.5075 - val_auc: 0.5919 - lr: 0.0010\n","Epoch 25/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5165 - auc: 0.5640 - val_loss: 0.5077 - val_auc: 0.5922 - lr: 0.0010\n","Epoch 26/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5155 - auc: 0.5694 - val_loss: 0.5054 - val_auc: 0.5927 - lr: 9.0000e-04\n","Epoch 27/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5167 - auc: 0.5614 - val_loss: 0.5193 - val_auc: 0.5943 - lr: 9.0000e-04\n","Epoch 28/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5157 - auc: 0.5674 - val_loss: 0.5071 - val_auc: 0.5937 - lr: 9.0000e-04\n","Epoch 29/200\n","254/254 [==============================] - 3s 11ms/step - loss: 0.5165 - auc: 0.5625 - val_loss: 0.5057 - val_auc: 0.5932 - lr: 9.0000e-04\n","Epoch 30/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5169 - auc: 0.5579 - val_loss: 0.5093 - val_auc: 0.5934 - lr: 9.0000e-04\n","Epoch 31/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5167 - auc: 0.5585 - val_loss: 0.5103 - val_auc: 0.5926 - lr: 9.0000e-04\n","Epoch 32/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5165 - auc: 0.5632 - val_loss: 0.5127 - val_auc: 0.5896 - lr: 8.1000e-04\n","Epoch 33/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5159 - auc: 0.5660 - val_loss: 0.5060 - val_auc: 0.5947 - lr: 8.1000e-04\n","Epoch 34/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5167 - auc: 0.5590 - val_loss: 0.5052 - val_auc: 0.5914 - lr: 8.1000e-04\n","Epoch 35/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5170 - auc: 0.5557 - val_loss: 0.5235 - val_auc: 0.5800 - lr: 8.1000e-04\n","Epoch 36/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5161 - auc: 0.5645 - val_loss: 0.5056 - val_auc: 0.5935 - lr: 8.1000e-04\n","Epoch 37/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5162 - auc: 0.5660 - val_loss: 0.5144 - val_auc: 0.5947 - lr: 7.2900e-04\n","Epoch 38/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5171 - auc: 0.5581 - val_loss: 0.5066 - val_auc: 0.5947 - lr: 7.2900e-04\n","Epoch 39/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5163 - auc: 0.5623 - val_loss: 0.5081 - val_auc: 0.5926 - lr: 7.2900e-04\n","Epoch 40/200\n","254/254 [==============================] - 3s 11ms/step - loss: 0.5165 - auc: 0.5615 - val_loss: 0.5055 - val_auc: 0.5941 - lr: 7.2900e-04\n","Epoch 41/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5164 - auc: 0.5628 - val_loss: 0.5061 - val_auc: 0.5925 - lr: 7.2900e-04\n","Epoch 42/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5153 - auc: 0.5704 - val_loss: 0.5286 - val_auc: 0.5943 - lr: 6.5610e-04\n","Epoch 43/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5171 - auc: 0.5593 - val_loss: 0.5104 - val_auc: 0.5944 - lr: 6.5610e-04\n","Epoch 44/200\n","254/254 [==============================] - 3s 10ms/step - loss: 0.5161 - auc: 0.5629 - val_loss: 0.5293 - val_auc: 0.5899 - lr: 6.5610e-04\n","fold #7\n","Epoch 1/200\n","250/250 [==============================] - 5s 12ms/step - loss: 0.6142 - auc: 0.5053 - val_loss: 0.5043 - val_auc: 0.5553 - lr: 0.0010\n","Epoch 2/200\n","250/250 [==============================] - 3s 10ms/step - loss: 0.5369 - auc: 0.5211 - val_loss: 0.5050 - val_auc: 0.5514 - lr: 0.0010\n","Epoch 3/200\n","250/250 [==============================] - 3s 11ms/step - loss: 0.5274 - auc: 0.5283 - val_loss: 0.5068 - val_auc: 0.5513 - lr: 0.0010\n","Epoch 4/200\n","250/250 [==============================] - 3s 10ms/step - loss: 0.5236 - auc: 0.5495 - val_loss: 0.5081 - val_auc: 0.5716 - lr: 0.0010\n","Epoch 5/200\n","250/250 [==============================] - 3s 11ms/step - loss: 0.5221 - auc: 0.5559 - val_loss: 0.5038 - val_auc: 0.5672 - lr: 0.0010\n","Epoch 6/200\n","250/250 [==============================] - 3s 11ms/step - loss: 0.5220 - auc: 0.5562 - val_loss: 0.5040 - val_auc: 0.5819 - lr: 0.0010\n","Epoch 7/200\n","250/250 [==============================] - 3s 11ms/step - loss: 0.5216 - auc: 0.5575 - val_loss: 0.5036 - val_auc: 0.5833 - lr: 0.0010\n","Epoch 8/200\n","250/250 [==============================] - 3s 11ms/step - loss: 0.5213 - auc: 0.5634 - val_loss: 0.5008 - val_auc: 0.5813 - lr: 0.0010\n","Epoch 9/200\n","250/250 [==============================] - 3s 10ms/step - loss: 0.5210 - auc: 0.5628 - val_loss: 0.5001 - val_auc: 0.5833 - lr: 0.0010\n","Epoch 10/200\n","250/250 [==============================] - 3s 10ms/step - loss: 0.5209 - auc: 0.5640 - val_loss: 0.5010 - val_auc: 0.5813 - lr: 0.0010\n","Epoch 11/200\n","250/250 [==============================] - 3s 10ms/step - loss: 0.5209 - auc: 0.5610 - val_loss: 0.5045 - val_auc: 0.5851 - lr: 0.0010\n","Epoch 12/200\n","250/250 [==============================] - 3s 10ms/step - loss: 0.5205 - auc: 0.5652 - val_loss: 0.5132 - val_auc: 0.5845 - lr: 0.0010\n","Epoch 13/200\n","250/250 [==============================] - 3s 10ms/step - loss: 0.5213 - auc: 0.5619 - val_loss: 0.5132 - val_auc: 0.5738 - lr: 0.0010\n","Epoch 14/200\n","250/250 [==============================] - 3s 10ms/step - loss: 0.5211 - auc: 0.5607 - val_loss: 0.5031 - val_auc: 0.5832 - lr: 0.0010\n","Epoch 15/200\n","250/250 [==============================] - 3s 10ms/step - loss: 0.5201 - auc: 0.5675 - val_loss: 0.5009 - val_auc: 0.5820 - lr: 0.0010\n","Epoch 16/200\n","250/250 [==============================] - 3s 11ms/step - loss: 0.5207 - auc: 0.5642 - val_loss: 0.4989 - val_auc: 0.5856 - lr: 0.0010\n","Epoch 17/200\n","250/250 [==============================] - 3s 11ms/step - loss: 0.5204 - auc: 0.5662 - val_loss: 0.5056 - val_auc: 0.5823 - lr: 0.0010\n","Epoch 18/200\n","250/250 [==============================] - 3s 11ms/step - loss: 0.5207 - auc: 0.5639 - val_loss: 0.5057 - val_auc: 0.5871 - lr: 0.0010\n","Epoch 19/200\n","250/250 [==============================] - 3s 10ms/step - loss: 0.5199 - auc: 0.5705 - val_loss: 0.5028 - val_auc: 0.5865 - lr: 0.0010\n","Epoch 20/200\n","250/250 [==============================] - 3s 11ms/step - loss: 0.5206 - auc: 0.5638 - val_loss: 0.5054 - val_auc: 0.5869 - lr: 0.0010\n","Epoch 21/200\n","250/250 [==============================] - 3s 10ms/step - loss: 0.5200 - auc: 0.5670 - val_loss: 0.5359 - val_auc: 0.5732 - lr: 0.0010\n","Epoch 22/200\n","250/250 [==============================] - 3s 10ms/step - loss: 0.5204 - auc: 0.5664 - val_loss: 0.5061 - val_auc: 0.5860 - lr: 0.0010\n","Epoch 23/200\n","250/250 [==============================] - 3s 10ms/step - loss: 0.5196 - auc: 0.5712 - val_loss: 0.4994 - val_auc: 0.5854 - lr: 0.0010\n","Epoch 24/200\n","250/250 [==============================] - 3s 10ms/step - loss: 0.5205 - auc: 0.5644 - val_loss: 0.4992 - val_auc: 0.5852 - lr: 0.0010\n","Epoch 25/200\n","250/250 [==============================] - 3s 11ms/step - loss: 0.5191 - auc: 0.5748 - val_loss: 0.5021 - val_auc: 0.5828 - lr: 0.0010\n","Epoch 26/200\n","250/250 [==============================] - 3s 10ms/step - loss: 0.5192 - auc: 0.5736 - val_loss: 0.4991 - val_auc: 0.5853 - lr: 0.0010\n","fold #8\n","Epoch 1/200\n","246/246 [==============================] - 5s 12ms/step - loss: 0.6019 - auc: 0.4946 - val_loss: 0.5210 - val_auc: 0.5560 - lr: 0.0010\n","Epoch 2/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5279 - auc: 0.5125 - val_loss: 0.5173 - val_auc: 0.5866 - lr: 0.0010\n","Epoch 3/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5178 - auc: 0.5393 - val_loss: 0.5173 - val_auc: 0.5741 - lr: 0.0010\n","Epoch 4/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5163 - auc: 0.5370 - val_loss: 0.5181 - val_auc: 0.5591 - lr: 0.0010\n","Epoch 5/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5143 - auc: 0.5465 - val_loss: 0.5229 - val_auc: 0.5490 - lr: 0.0010\n","Epoch 6/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5128 - auc: 0.5571 - val_loss: 0.5231 - val_auc: 0.5866 - lr: 0.0010\n","Epoch 7/200\n","246/246 [==============================] - 3s 11ms/step - loss: 0.5135 - auc: 0.5526 - val_loss: 0.5186 - val_auc: 0.5536 - lr: 0.0010\n","Epoch 8/200\n","246/246 [==============================] - 3s 11ms/step - loss: 0.5126 - auc: 0.5582 - val_loss: 0.5243 - val_auc: 0.5594 - lr: 0.0010\n","Epoch 9/200\n","246/246 [==============================] - 3s 11ms/step - loss: 0.5124 - auc: 0.5590 - val_loss: 0.5181 - val_auc: 0.5586 - lr: 0.0010\n","Epoch 10/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5136 - auc: 0.5505 - val_loss: 0.5143 - val_auc: 0.5865 - lr: 0.0010\n","Epoch 11/200\n","246/246 [==============================] - 3s 11ms/step - loss: 0.5130 - auc: 0.5549 - val_loss: 0.5251 - val_auc: 0.5769 - lr: 0.0010\n","Epoch 12/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5131 - auc: 0.5543 - val_loss: 0.5189 - val_auc: 0.5901 - lr: 0.0010\n","Epoch 13/200\n","246/246 [==============================] - 3s 11ms/step - loss: 0.5122 - auc: 0.5583 - val_loss: 0.5141 - val_auc: 0.5912 - lr: 0.0010\n","Epoch 14/200\n","246/246 [==============================] - 3s 11ms/step - loss: 0.5132 - auc: 0.5527 - val_loss: 0.5176 - val_auc: 0.5880 - lr: 0.0010\n","Epoch 15/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5131 - auc: 0.5516 - val_loss: 0.5158 - val_auc: 0.5674 - lr: 9.0000e-04\n","Epoch 16/200\n","246/246 [==============================] - 2s 10ms/step - loss: 0.5119 - auc: 0.5624 - val_loss: 0.5177 - val_auc: 0.5908 - lr: 9.0000e-04\n","Epoch 17/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5120 - auc: 0.5593 - val_loss: 0.5215 - val_auc: 0.5887 - lr: 9.0000e-04\n","Epoch 18/200\n","246/246 [==============================] - 3s 11ms/step - loss: 0.5118 - auc: 0.5619 - val_loss: 0.5134 - val_auc: 0.5815 - lr: 9.0000e-04\n","Epoch 19/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5129 - auc: 0.5530 - val_loss: 0.5165 - val_auc: 0.5918 - lr: 9.0000e-04\n","Epoch 20/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5124 - auc: 0.5584 - val_loss: 0.5141 - val_auc: 0.5880 - lr: 9.0000e-04\n","Epoch 21/200\n","246/246 [==============================] - 3s 11ms/step - loss: 0.5126 - auc: 0.5558 - val_loss: 0.5145 - val_auc: 0.5836 - lr: 9.0000e-04\n","Epoch 22/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5123 - auc: 0.5571 - val_loss: 0.5132 - val_auc: 0.5861 - lr: 8.1000e-04\n","Epoch 23/200\n","246/246 [==============================] - 3s 11ms/step - loss: 0.5114 - auc: 0.5633 - val_loss: 0.5143 - val_auc: 0.5854 - lr: 8.1000e-04\n","Epoch 24/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5119 - auc: 0.5643 - val_loss: 0.5123 - val_auc: 0.5887 - lr: 8.1000e-04\n","Epoch 25/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5115 - auc: 0.5636 - val_loss: 0.5117 - val_auc: 0.5891 - lr: 8.1000e-04\n","Epoch 26/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5123 - auc: 0.5588 - val_loss: 0.5167 - val_auc: 0.5848 - lr: 8.1000e-04\n","Epoch 27/200\n","246/246 [==============================] - 3s 11ms/step - loss: 0.5114 - auc: 0.5648 - val_loss: 0.5127 - val_auc: 0.5913 - lr: 8.1000e-04\n","Epoch 28/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5128 - auc: 0.5558 - val_loss: 0.5263 - val_auc: 0.5917 - lr: 8.1000e-04\n","Epoch 29/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5125 - auc: 0.5576 - val_loss: 0.5140 - val_auc: 0.5796 - lr: 8.1000e-04\n","Epoch 30/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5114 - auc: 0.5646 - val_loss: 0.5120 - val_auc: 0.5919 - lr: 8.1000e-04\n","Epoch 31/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5125 - auc: 0.5576 - val_loss: 0.5165 - val_auc: 0.5846 - lr: 8.1000e-04\n","Epoch 32/200\n","246/246 [==============================] - 3s 11ms/step - loss: 0.5119 - auc: 0.5593 - val_loss: 0.5127 - val_auc: 0.5889 - lr: 8.1000e-04\n","Epoch 33/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5119 - auc: 0.5608 - val_loss: 0.5258 - val_auc: 0.5904 - lr: 7.2900e-04\n","Epoch 34/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5124 - auc: 0.5559 - val_loss: 0.5129 - val_auc: 0.5880 - lr: 7.2900e-04\n","Epoch 35/200\n","246/246 [==============================] - 3s 10ms/step - loss: 0.5120 - auc: 0.5606 - val_loss: 0.5140 - val_auc: 0.5907 - lr: 7.2900e-04\n","fold #9\n","Epoch 1/200\n","242/242 [==============================] - 5s 12ms/step - loss: 0.6139 - auc: 0.4982 - val_loss: 0.5172 - val_auc: 0.5330 - lr: 0.0010\n","Epoch 2/200\n","242/242 [==============================] - 3s 10ms/step - loss: 0.5322 - auc: 0.5272 - val_loss: 0.5216 - val_auc: 0.5159 - lr: 0.0010\n","Epoch 3/200\n","242/242 [==============================] - 3s 10ms/step - loss: 0.5239 - auc: 0.5309 - val_loss: 0.5109 - val_auc: 0.5563 - lr: 0.0010\n","Epoch 4/200\n","242/242 [==============================] - 3s 11ms/step - loss: 0.5183 - auc: 0.5575 - val_loss: 0.5123 - val_auc: 0.5289 - lr: 0.0010\n","Epoch 5/200\n","242/242 [==============================] - 3s 11ms/step - loss: 0.5195 - auc: 0.5434 - val_loss: 0.5135 - val_auc: 0.5791 - lr: 0.0010\n","Epoch 6/200\n","242/242 [==============================] - 3s 10ms/step - loss: 0.5171 - auc: 0.5588 - val_loss: 0.5108 - val_auc: 0.5723 - lr: 0.0010\n","Epoch 7/200\n","242/242 [==============================] - 3s 11ms/step - loss: 0.5176 - auc: 0.5549 - val_loss: 0.5105 - val_auc: 0.5732 - lr: 0.0010\n","Epoch 8/200\n","242/242 [==============================] - 3s 11ms/step - loss: 0.5169 - auc: 0.5585 - val_loss: 0.5132 - val_auc: 0.5815 - lr: 0.0010\n","Epoch 9/200\n","242/242 [==============================] - 3s 11ms/step - loss: 0.5158 - auc: 0.5655 - val_loss: 0.5088 - val_auc: 0.5794 - lr: 0.0010\n","Epoch 10/200\n","242/242 [==============================] - 3s 11ms/step - loss: 0.5158 - auc: 0.5658 - val_loss: 0.5177 - val_auc: 0.5772 - lr: 0.0010\n","Epoch 11/200\n","242/242 [==============================] - 3s 11ms/step - loss: 0.5157 - auc: 0.5689 - val_loss: 0.5108 - val_auc: 0.5822 - lr: 0.0010\n","Epoch 12/200\n","242/242 [==============================] - 3s 10ms/step - loss: 0.5153 - auc: 0.5696 - val_loss: 0.5187 - val_auc: 0.5781 - lr: 0.0010\n","Epoch 13/200\n","242/242 [==============================] - 3s 10ms/step - loss: 0.5165 - auc: 0.5619 - val_loss: 0.5091 - val_auc: 0.5737 - lr: 0.0010\n","Epoch 14/200\n","242/242 [==============================] - 3s 11ms/step - loss: 0.5159 - auc: 0.5666 - val_loss: 0.5063 - val_auc: 0.5838 - lr: 0.0010\n","Epoch 15/200\n","242/242 [==============================] - 3s 10ms/step - loss: 0.5155 - auc: 0.5688 - val_loss: 0.5109 - val_auc: 0.5828 - lr: 0.0010\n","Epoch 16/200\n","242/242 [==============================] - 3s 11ms/step - loss: 0.5153 - auc: 0.5705 - val_loss: 0.5077 - val_auc: 0.5827 - lr: 0.0010\n","Epoch 17/200\n","242/242 [==============================] - 3s 11ms/step - loss: 0.5155 - auc: 0.5680 - val_loss: 0.5139 - val_auc: 0.5845 - lr: 0.0010\n","Epoch 18/200\n","242/242 [==============================] - 3s 11ms/step - loss: 0.5143 - auc: 0.5751 - val_loss: 0.5154 - val_auc: 0.5824 - lr: 0.0010\n","Epoch 19/200\n","242/242 [==============================] - 3s 11ms/step - loss: 0.5148 - auc: 0.5715 - val_loss: 0.5098 - val_auc: 0.5834 - lr: 0.0010\n","Epoch 20/200\n","242/242 [==============================] - 3s 11ms/step - loss: 0.5163 - auc: 0.5626 - val_loss: 0.5081 - val_auc: 0.5839 - lr: 0.0010\n","Epoch 21/200\n","242/242 [==============================] - 3s 11ms/step - loss: 0.5155 - auc: 0.5691 - val_loss: 0.5197 - val_auc: 0.5843 - lr: 0.0010\n","Epoch 22/200\n","242/242 [==============================] - 3s 11ms/step - loss: 0.5145 - auc: 0.5740 - val_loss: 0.5227 - val_auc: 0.5837 - lr: 0.0010\n","Epoch 23/200\n","242/242 [==============================] - 3s 11ms/step - loss: 0.5168 - auc: 0.5596 - val_loss: 0.5086 - val_auc: 0.5796 - lr: 0.0010\n","Epoch 24/200\n","242/242 [==============================] - 3s 11ms/step - loss: 0.5166 - auc: 0.5611 - val_loss: 0.5106 - val_auc: 0.5836 - lr: 9.0000e-04\n","fold #10\n","Epoch 1/200\n","252/252 [==============================] - 5s 12ms/step - loss: 0.5993 - auc: 0.5052 - val_loss: 0.5175 - val_auc: 0.5538 - lr: 0.0010\n","Epoch 2/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5285 - auc: 0.5135 - val_loss: 0.5189 - val_auc: 0.5296 - lr: 0.0010\n","Epoch 3/200\n","252/252 [==============================] - 3s 11ms/step - loss: 0.5208 - auc: 0.5218 - val_loss: 0.5190 - val_auc: 0.5767 - lr: 0.0010\n","Epoch 4/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5171 - auc: 0.5429 - val_loss: 0.5168 - val_auc: 0.5530 - lr: 0.0010\n","Epoch 5/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5166 - auc: 0.5447 - val_loss: 0.5160 - val_auc: 0.5698 - lr: 0.0010\n","Epoch 6/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5150 - auc: 0.5549 - val_loss: 0.5151 - val_auc: 0.5810 - lr: 0.0010\n","Epoch 7/200\n","252/252 [==============================] - 3s 11ms/step - loss: 0.5151 - auc: 0.5536 - val_loss: 0.5134 - val_auc: 0.5829 - lr: 0.0010\n","Epoch 8/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5137 - auc: 0.5648 - val_loss: 0.5145 - val_auc: 0.5824 - lr: 0.0010\n","Epoch 9/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5146 - auc: 0.5562 - val_loss: 0.5103 - val_auc: 0.5888 - lr: 0.0010\n","Epoch 10/200\n","252/252 [==============================] - 3s 11ms/step - loss: 0.5140 - auc: 0.5617 - val_loss: 0.5102 - val_auc: 0.5847 - lr: 0.0010\n","Epoch 11/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5134 - auc: 0.5624 - val_loss: 0.5151 - val_auc: 0.5890 - lr: 0.0010\n","Epoch 12/200\n","252/252 [==============================] - 3s 11ms/step - loss: 0.5145 - auc: 0.5583 - val_loss: 0.5112 - val_auc: 0.5872 - lr: 0.0010\n","Epoch 13/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5129 - auc: 0.5671 - val_loss: 0.5105 - val_auc: 0.5896 - lr: 0.0010\n","Epoch 14/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5132 - auc: 0.5661 - val_loss: 0.5103 - val_auc: 0.5894 - lr: 0.0010\n","Epoch 15/200\n","252/252 [==============================] - 3s 11ms/step - loss: 0.5130 - auc: 0.5667 - val_loss: 0.5104 - val_auc: 0.5894 - lr: 0.0010\n","Epoch 16/200\n","252/252 [==============================] - 3s 11ms/step - loss: 0.5129 - auc: 0.5688 - val_loss: 0.5306 - val_auc: 0.5794 - lr: 0.0010\n","Epoch 17/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5137 - auc: 0.5613 - val_loss: 0.5219 - val_auc: 0.5885 - lr: 0.0010\n","Epoch 18/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5132 - auc: 0.5661 - val_loss: 0.5110 - val_auc: 0.5869 - lr: 0.0010\n","Epoch 19/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5132 - auc: 0.5668 - val_loss: 0.5102 - val_auc: 0.5904 - lr: 0.0010\n","Epoch 20/200\n","252/252 [==============================] - 3s 10ms/step - loss: 0.5137 - auc: 0.5583 - val_loss: 0.5144 - val_auc: 0.5885 - lr: 0.0010\n"]}],"source":["# training with 10-fold cross validation\n","for num in folds_dict.keys():\n","    print(f'fold {num}')\n","\n","    X_df_train = df_train[df_train['product_code'].isin(folds_dict[num][0])]\n","    X_train = X_df_train[features].values\n","    y_df_train = df_train[df_train['product_code'].isin(folds_dict[num][0])]\n","    y_train = y_df_train['failure'].values\n","    X_df_valid = df_train[df_train['product_code'].isin(folds_dict[num][1])]\n","    X_valid = X_df_valid[features].values\n","    y_df_valid = df_train[df_train['product_code'].isin(folds_dict[num][1])]\n","    y_valid = y_df_valid['failure'].values\n","\n","    model = build_model(len(X_train))\n","    es_callbacks = tf.keras.callbacks.EarlyStopping(\n","           patience=10, restore_best_weights=True)\n","\n","    lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n","           monitor=\"auc\", factor=0.9, patience=5,\n","           verbose=0, mode=\"max\", min_delta=0.0001,\n","           cooldown=0, min_lr=0)\n","\n","    model.compile(optimizer=tfa.optimizers.AdamW(\n","                learning_rate=1e-3, weight_decay=1e-3),\n","                loss=\"BinaryCrossentropy\", metrics=[\"AUC\"])\n","\n","    model.fit(\n","         X_train, y_train, batch_size=64, epochs=200,\n","         callbacks=[es_callbacks, lr_scheduler],\n","         validation_data=(X_valid, y_valid))"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1673310929495,"user":{"displayName":"張可晴","userId":"06130326083553074662"},"user_tz":-480},"id":"7MlvqYJfJPTn"},"outputs":[],"source":["model.save('model.h5')\n","!cp model.h5 ./gdrive/MyDrive/Final/model.h5"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"16847d31023ea665895a656bb61aa803bfcdc09ea951ca19f549021cdfa8d14f"}}},"nbformat":4,"nbformat_minor":0}